{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸªš How to Web Scrape [DataJobs.com](https://datajobs.com/)\n",
    "\n",
    "*Source: ðŸ¤– [Data Jobs Webscraper](https://github.com/ColinB19/datajobswebscraper) Repo*\n",
    "\n",
    "If you're like me, endlessly scrolling through job postings to gain insights on what you should learn becomes an exercise in futility. After scrolling through hundreds of jobs for hours on end, it is just too difficult to know which skills are the most important. I need a way to digest all of the information from thousands of job postings simultaneously. That is what this project aims to do: pull information from online job boards to gain valuable job-hunting insights!\n",
    "\n",
    "**Web Scraping** is the programmatic retrieval of data from websites. In general, the web scraping bot navigates to a desired webpage and extracts or parses the source HTML for the desired data. \n",
    "\n",
    "[**Selenium**](https://selenium-python.readthedocs.io/) is a web scraping framework in Python that uses a real browser instance to navigate through webpages, interact with page elements, and extract information. While you can use most browsers with selenium, the suggested browser is Google Chrome. \n",
    "\n",
    "<img src=\"IMG/DataJobs_Header.png\">\n",
    "\n",
    "This notebook will demonstrate how to scrape job entries from [**DataJobs.com**](https://datajobs.com/) using **Selenium** This serves as a guide informing the larger scraper that incorporates jobs from [**Indeed.com**](https://www.indeed.com/). Please see the [**Full Webscraping**](https://github.com/ColinB19/datajobswebscraper/blob/master/Webscrape_DataJobs.ipynb) notebook for the full end-product. \n",
    "\n",
    "> **Note**: You should always check a website's *robots.txt* file to ensure that scraping is allowed. DataJobs has no restrictions on web scraping, so we are good to go. If you want to check, just type in the websites base URL + `\"/robots.txt\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "- [**Selenium**](https://selenium-python.readthedocs.io/): web scraping library allowing us to extract information from the internet\n",
    "- [**Pandas**](https://pandas.pydata.org/docs/): data management library that we will use to conveniently store and manipulate the data\n",
    "- [**regex**](https://github.com/mrabarnett/mrab-regex): a text parsing library that will allow us to search through the HTML from the web pages we scrape to find key information.\n",
    "- [**webdriver_manager**](https://github.com/SergeyPirogov/webdriver_manager): a package that enables automatic download of the proper chromium drivers.\n",
    "\n",
    "> **Regex** is an extension built on top of the built-in [**re**](https://docs.python.org/3/library/re.html) module with some extended functionality. I tend to use it by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Driver\n",
    "Now we can set up the Chrome driver. I use the ChromeDriverManager class from the **webdriver_manager** package. This enables automatic download of the Chromium drivers so you do not need to manually install and point **Selenium** to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enables automatic installation of chrome drivers\n",
    "service = Service(ChromeDriverManager().install())\n",
    "# set up chrome driver\n",
    "driver = Chrome(service=service)\n",
    "\n",
    "# navigate to DataJobs.com\n",
    "site_url = \"https://datajobs.com/\"\n",
    "driver.get(site_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page Navigation\n",
    "\n",
    "Now that we have navigated to the site page, let's click on the `Data Science Jobs/Analytics` link to get a list of all data science roles available on the platform.\n",
    "\n",
    "> **Note**: in the [**Full Webscraping**](https://github.com/ColinB19/datajobswebscraper/blob/master/Webscrape_DataJobs.ipynb) notebook, we scrape both the Data Science and Data Engineering positions. \n",
    "\n",
    "<img src=\"IMG/DataJobs_link1-edit.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_time = 3\n",
    "dsa_jobs_list = WebDriverWait(driver, wait_time).until(\n",
    "    EC.element_to_be_clickable(\n",
    "        (By.XPATH, \"//a[contains(text(), 'Data Science Jobs / Analytics')]\")\n",
    "    )\n",
    ")\n",
    "dsa_jobs_list.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Job Information\n",
    "\n",
    "Now we can scroll through the jobs and pull information. The scraper should grab all of the entries on a page, then go to the next page and repeat the process. What will we scrape?\n",
    "\n",
    "1. The link to the job posting - so we can scrape job descriptions later!\n",
    "2. The Job Title\n",
    "3. The Company\n",
    "4. Pay information (if available)\n",
    "5. The Location\n",
    "\n",
    "<img src=\"IMG/scroll-edit.gif\" height=400 width=600>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the regex we will use to parse the HTML\n",
    "dj_pattern = r\"<a href=\\\"(.*)\\\"><strong>(.*)</strong> â€“ <span [^\\>]*>(.*)</span></a>[\\n\\s]*</div>[\\n\\s]*<div[^\\>]*>[\\n\\s]*<em>[\\n\\s]*<span[^\\>]*>(.*)</span>[\\n\\s]*[\\&nbsp;\\â€¢]*[\\n\\s]*\\$*([\\d,]*)[â€“\\s]*\\$*([\\d,]*)[\\n\\s]*</em>\"\n",
    "\n",
    "# these are URL paths to the specific job lists for each job type on DataJobs\n",
    "board_paths = [\"/Data-Science-Jobs\", \"/Data-Engineering-Jobs\"]\n",
    "\n",
    "job_meta = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"url\",\n",
    "                \"title\",\n",
    "                \"company\",\n",
    "                \"location\",\n",
    "                \"salary_lower\",\n",
    "                \"salary_upper\"\n",
    "            ]\n",
    "        )\n",
    "# loop through the boards available\n",
    "for bp in board_paths:\n",
    "    if bp == \"/Data-Science-Jobs\":\n",
    "        cat = \"Data Science & Analytics\"\n",
    "    else:\n",
    "        cat = \"Data Engineering\"\n",
    "    # load into the webpage\n",
    "    driver.get(site_url + bp)\n",
    "    more_pages = True  # will kill the loop when there are no more pages\n",
    "    i = 0  # just a counter to kill the loop just in case\n",
    "    while more_pages:\n",
    "        # grab page source html\n",
    "        page_html = driver.page_source\n",
    "\n",
    "        # grab job info\n",
    "        fall = re.findall(dj_pattern, page_html)\n",
    "        \n",
    "        # zip the info into a dict for easy DataFrame-ability\n",
    "        fall_cols = [\n",
    "            dict(\n",
    "                zip(\n",
    "                    job_meta.columns,\n",
    "                    (\n",
    "                        (\n",
    "                            y.replace(\"&amp;\", \"&\") # this removes some HTML stuff to not confuse the CSV format\n",
    "                            .replace(\"&amp,\", \"&\")\n",
    "                            .replace(\"&nbsp;\", \" \")\n",
    "                            .replace(\"&nbsp,\", \" \")\n",
    "                            if type(y) == str\n",
    "                            else y\n",
    "                        )\n",
    "                        for y in x\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            for x in fall\n",
    "        ]\n",
    "        # add to dataframe\n",
    "        job_meta = pd.concat(\n",
    "            [job_meta, pd.DataFrame(fall_cols)], ignore_index=True\n",
    "        )\n",
    "\n",
    "        if i == 10:\n",
    "            # stop after 10 pages\n",
    "            more_pages = False\n",
    "\n",
    "        # try to go to next page\n",
    "        try:\n",
    "            next_page = WebDriverWait(driver, wait_time).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, \"//a[contains(text(), 'NEXT PAGE')]\")\n",
    "                )\n",
    "            )\n",
    "            next_page.click()\n",
    "            i += 1\n",
    "        except:\n",
    "            print(f\"END OF SEARCH RESULTS: {site_url} || {bp}\")\n",
    "            more_pages = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_lower</th>\n",
       "      <th>salary_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Columbia-University-Data-Science-Institute/Po...</td>\n",
       "      <td>Postdoctoral Research Scientist</td>\n",
       "      <td>Columbia University, Data Science Institute</td>\n",
       "      <td>New York City</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/the-D-E-Shaw-Group/People-Analytics-Data-Scie...</td>\n",
       "      <td>People Analytics - Data Science &amp; Reporting An...</td>\n",
       "      <td>The D. E. Shaw Group</td>\n",
       "      <td>New York City</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/the-Ohio-State-University/Lead-Data-Scientist...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>The Ohio State University</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/DraftKings/Lead-Data-Science-Engineer-Job~100873</td>\n",
       "      <td>Lead Data Science Engineer</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>Remote</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Shopify/Staff-Data-Scientist-Americas-Remote-...</td>\n",
       "      <td>Staff Data Scientist (Americas - Remote)</td>\n",
       "      <td>Shopify</td>\n",
       "      <td>Remote</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  /Columbia-University-Data-Science-Institute/Po...   \n",
       "1  /the-D-E-Shaw-Group/People-Analytics-Data-Scie...   \n",
       "2  /the-Ohio-State-University/Lead-Data-Scientist...   \n",
       "3  /DraftKings/Lead-Data-Science-Engineer-Job~100873   \n",
       "4  /Shopify/Staff-Data-Scientist-Americas-Remote-...   \n",
       "\n",
       "                                               title  \\\n",
       "0                    Postdoctoral Research Scientist   \n",
       "1  People Analytics - Data Science & Reporting An...   \n",
       "2                               Lead Data Scientist    \n",
       "3                         Lead Data Science Engineer   \n",
       "4           Staff Data Scientist (Americas - Remote)   \n",
       "\n",
       "                                       company       location salary_lower  \\\n",
       "0  Columbia University, Data Science Institute  New York City                \n",
       "1                         The D. E. Shaw Group  New York City                \n",
       "2                  The Ohio State University     Columbus, OH                \n",
       "3                                   DraftKings         Remote                \n",
       "4                                      Shopify         Remote                \n",
       "\n",
       "  salary_upper  \n",
       "0               \n",
       "1               \n",
       "2               \n",
       "3               \n",
       "4               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check out our data!\n",
    "job_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Job Descriptions\n",
    "\n",
    "Lastly, let's scrape job descriptions. This is so we can find some popular skills and terms for data jobs.\n",
    "\n",
    "<img src=\"IMG/JobPost_HTML_example.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't find this job: Data Science Senior Engineer\n"
     ]
    }
   ],
   "source": [
    "def cleanhtml(html_string: str) -> str:\n",
    "    \"\"\"Regex pattern to match and remove all html tags and comments, leaving plain text.\"\"\"\n",
    "    html_string2 = re.sub(\"(<!--.*?-->)\", \"\", html_string, flags=re.DOTALL)\n",
    "    cleaned_html = re.sub(\n",
    "        \"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\", \" \", html_string2\n",
    "    )\n",
    "    return cleaned_html\n",
    "\n",
    "# list to hold description text\n",
    "job_desc_list = []\n",
    "for _, job in job_meta.iterrows():\n",
    "    # set up the URL so the driver can navigate there\n",
    "    job_url = site_url + job[\"url\"][1:]\n",
    "    # navigate to the job posting\n",
    "    driver.get(job_url)\n",
    "    # grab job desc element\n",
    "    try:\n",
    "        job_descr = WebDriverWait(driver, wait_time).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (\n",
    "                    By.XPATH,\n",
    "                    \"//div[@id='job_description']//*[@class='jobpost-table-cell-2']\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        print(f\"I can't find this job: {job['title']}\")\n",
    "        continue\n",
    "\n",
    "    # get html\n",
    "    job_desc_clean = (\n",
    "        cleanhtml(job_descr.get_attribute(\"innerHTML\"))\n",
    "        .replace(\"&amp;\", \"&\") # this removes some HTML stuff to not confuse the CSV format\n",
    "        .replace(\"&amp,\", \"&\")\n",
    "        .replace(\"&nbsp;\", \" \")\n",
    "        .replace(\"&nbsp,\", \" \")\n",
    "    )\n",
    "    job_desc_list.append(\n",
    "        {\n",
    "            \"title\": job[\"title\"],\n",
    "            \"company\": job[\"company\"],\n",
    "            \"desc\": job_desc_clean,\n",
    "        }\n",
    "    )\n",
    "# make a pandas dataframe\n",
    "job_descs = pd.DataFrame(job_desc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Postdoctoral Research Scientist</td>\n",
       "      <td>Columbia University, Data Science Institute</td>\n",
       "      <td>\\n                         The Data Science In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People Analytics - Data Science &amp; Reporting An...</td>\n",
       "      <td>The D. E. Shaw Group</td>\n",
       "      <td>\\n                          OVERVIEW:   The D....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>The Ohio State University</td>\n",
       "      <td>\\n                          Department:   Publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Science Engineer</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>\\n                         BE THE STRATEGY BEH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staff Data Scientist (Americas - Remote)</td>\n",
       "      <td>Shopify</td>\n",
       "      <td>\\n                          Staff Data Scienti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                    Postdoctoral Research Scientist   \n",
       "1  People Analytics - Data Science & Reporting An...   \n",
       "2                               Lead Data Scientist    \n",
       "3                         Lead Data Science Engineer   \n",
       "4           Staff Data Scientist (Americas - Remote)   \n",
       "\n",
       "                                       company  \\\n",
       "0  Columbia University, Data Science Institute   \n",
       "1                         The D. E. Shaw Group   \n",
       "2                  The Ohio State University     \n",
       "3                                   DraftKings   \n",
       "4                                      Shopify   \n",
       "\n",
       "                                                desc  \n",
       "0  \\n                         The Data Science In...  \n",
       "1  \\n                          OVERVIEW:   The D....  \n",
       "2  \\n                          Department:   Publ...  \n",
       "3  \\n                         BE THE STRATEGY BEH...  \n",
       "4  \\n                          Staff Data Scienti...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check out our data!\n",
    "job_descs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
