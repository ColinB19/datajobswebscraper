{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Web Scrape [DataJobs.com](https://datajobs.com/)\n",
    "\n",
    "<img src=\"BLOG/DataJObs_Header.png\">\n",
    "\n",
    "This notebook will take you through how to scrape job entries from DataJobs.com! This serves as a guide informing the larger scraper that incorporates jobs from [Indeed.com](https://www.indeed.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enables automatic installation of chrome drivers\n",
    "service = Service(ChromeDriverManager().install())\n",
    "# set up chrome driver\n",
    "driver = Chrome(service=service)\n",
    "\n",
    "# navigate to DataJobs.com\n",
    "site_url = \"https://datajob.com/\"\n",
    "driver.get(site_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_time = 3\n",
    "dsa_jobs_list = WebDriverWait(driver, wait_time).until(\n",
    "    EC.element_to_be_clickable(\n",
    "        (By.XPATH, \"//a[contains(text(), 'Data Science Jobs / Analytics')]\")\n",
    "    )\n",
    ")\n",
    "dsa_jobs_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_paths = [\"/Data-Science-Jobs\", \"/Data-Engineering-Jobs\"]\n",
    "# loop through the boards available\n",
    "for bp in board_paths:\n",
    "    if bp == \"/Data-Science-Jobs\":\n",
    "        cat = \"Data Science & Analytics\"\n",
    "    else:\n",
    "        cat = \"Data Engineering\"\n",
    "    # load into the webpage\n",
    "    self._driver.get(self._site_url + bp)\n",
    "    more_pages = True  # will kill the loop when there are no more pages\n",
    "    i = 0  # just a counter to kill the loop just in case\n",
    "    while more_pages:\n",
    "        # grab page source html\n",
    "        page_html = self._driver.page_source\n",
    "\n",
    "        # grab job info\n",
    "        fall = re.findall(dj_pattern, page_html)\n",
    "        \n",
    "        # zip the info into a dict for easy DataFrame-ability\n",
    "        fall_cols = [\n",
    "            dict(\n",
    "                zip(\n",
    "                    self.job_meta.columns,\n",
    "                    (\n",
    "                        (\n",
    "                            y.replace(\"&amp;\", \"&\") # this removes some HTML stuff to not confuse the CSV format\n",
    "                            .replace(\"&amp,\", \"&\")\n",
    "                            .replace(\"&nbsp;\", \" \")\n",
    "                            .replace(\"&nbsp,\", \" \")\n",
    "                            if type(y) == str\n",
    "                            else y\n",
    "                        )\n",
    "                        for y in x\n",
    "                    )\n",
    "                    + (cat,),\n",
    "                )\n",
    "            )\n",
    "            for x in fall\n",
    "        ]\n",
    "        # add to dataframe\n",
    "        self.job_meta = pd.concat(\n",
    "            [self.job_meta, pd.DataFrame(fall_cols)], ignore_index=True\n",
    "        )\n",
    "\n",
    "        if i == 300:\n",
    "            # stop after 300 pages\n",
    "            more_pages = False\n",
    "\n",
    "        # try to go to next page\n",
    "        try:\n",
    "            next_page = WebDriverWait(self._driver, wait_time).until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, \"//a[contains(text(), 'NEXT PAGE')]\")\n",
    "                )\n",
    "            )\n",
    "            next_page.click()\n",
    "            i += 1\n",
    "        except:\n",
    "            logging.info(f\"END OF SEARCH RESULTS: {self._site_url} || {bp}\")\n",
    "            more_pages = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # scrape the job description from the job posting\n",
    "\n",
    "# list to hold description text\n",
    "job_desc_list = []\n",
    "for _, job in self.job_meta.iterrows():\n",
    "    # set up the URL so the driver can navigate there\n",
    "    job_url = self._site_url + job[\"url\"][1:]\n",
    "    # navigate to the job posting\n",
    "    self._driver.get(job_url)\n",
    "    # grab job desc element\n",
    "    try:\n",
    "        job_descr = WebDriverWait(self._driver, wait_time).until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (\n",
    "                    By.XPATH,\n",
    "                    \"//div[@id='job_description']//*[@class='jobpost-table-cell-2']\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        logging.error(f\"I can't find this job: {job['title']} || {self._site_url}\")\n",
    "        continue\n",
    "\n",
    "    # get html\n",
    "    job_desc_clean = (\n",
    "        cleanhtml(job_descr.get_attribute(\"innerHTML\"))\n",
    "        .replace(\"&amp;\", \"&\") # this removes some HTML stuff to not confuse the CSV format\n",
    "        .replace(\"&amp,\", \"&\")\n",
    "        .replace(\"&nbsp;\", \" \")\n",
    "        .replace(\"&nbsp,\", \" \")\n",
    "    )\n",
    "    job_desc_list.append(\n",
    "        {\n",
    "            \"job_id\": job[\"job_id\"],\n",
    "            \"title\": job[\"title\"],\n",
    "            \"company\": job[\"company\"],\n",
    "            \"desc\": job_desc_clean,\n",
    "        }\n",
    "    )\n",
    "return job_desc_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wellfound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
